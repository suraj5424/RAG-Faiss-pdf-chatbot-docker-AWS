# LOCAL HOST READY

services:
  backend:
    build: ./rag_pdfchatbot_backend
    container_name: rag-backend
    ports:
      - "8000:8000"
    env_file:
      - .env  # Backend uses environment variables like model selection
    restart: always
    volumes:
      - ./onnx_model:/app/onnx_model  # Mount models externally to switch at runtime
    mem_limit: 600m
    cpus: 0.5

  frontend:
    build: ./rag_pdfchatbot_frontend
    container_name: rag-frontend
    ports:
      - "8501:8501"
    depends_on:
      - backend
    restart: always
    mem_limit: 350m
    cpus: 0.4

  nginx:
    build: ./nginx
    container_name: nginx-reverse-proxy
    ports:
      - "80:80"  # Public port for all traffic
    depends_on:
      - frontend
      - backend
    restart: always


# # AWS DEPLOYMENT READY

# services:
#   backend:
#     image: suraj5424/final-rag_pdfchatbot_backend:1.0
#     container_name: rag-backend
#     env_file:
#       - .env
#     restart: always
#     mem_limit: 600m
#     cpus: 0.5
#     networks:
#       - rag-net

#   frontend:
#     image: suraj5424/latest-rag_pdfchatbot_frontend:1.0
#     container_name: rag-frontend
#     depends_on:
#       - backend
#     restart: always
#     mem_limit: 350m
#     cpus: 0.4
#     networks:
#       - rag-net

#   nginx:
#     build: ./nginx
#     container_name: nginx-reverse-proxy
#     ports:
#       - "80:80"
#     depends_on:
#       - frontend
#       - backend
#     restart: always
#     networks:
#       - rag-net

# networks:
#   rag-net:
#     driver: bridge